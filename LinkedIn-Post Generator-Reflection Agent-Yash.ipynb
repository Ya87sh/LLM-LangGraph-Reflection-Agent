{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boiler Plate Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, List, Literal, Optional, Tuple\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Define the State (Shared Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph State\n",
    "class State(TypedDict):\n",
    "    iteration: int\n",
    "    topic: str\n",
    "    post_content: Optional[str]\n",
    "    post_content_revise: Optional[str]\n",
    "    critique_feedback: str\n",
    "    verdict: Optional[Literal[\"good\", \"rework\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Define Prompt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return prompt to generate LinkedIn post\n",
    "def get_generate_post_prompt() -> str:\n",
    "    \n",
    "    # Define System Content\n",
    "    systemContent = \"\"\"\n",
    "    You are an expert LinkedIn content strategist specializing in creating highly engaging posts that drive meaningful professional conversations.\n",
    "    Your task is to generate a LinkedIn post about {topic} while incorporating any previous feedback provided in {critique-feedback}.\n",
    "\n",
    "    Key Objectives:\n",
    "    Generate posts that spark professional discussions and encourage meaningful engagement\n",
    "    Maintain authenticity and avoid overly promotional language\n",
    "    Incorporate storytelling elements when relevant\n",
    "    Follow LinkedIn best practices for content structure and formatting\n",
    "    Adapt and improve based on provided critique feedback\n",
    "\n",
    "    Context Understanding:\n",
    "    Topic: {topic}\n",
    "    Previous Feedback: {critique-feedback}\n",
    "    [Note: For initial generation, feedback will be empty. For subsequent iterations, incorporate the feedback to improve the post.]\n",
    "    \"\"\"\n",
    "\n",
    "    # List of Messages for the LLM\n",
    "    messages = [(\"system\", systemContent), (\"human\", \"{topic} {critique-feedback}\")]\n",
    "\n",
    "    # Return the Prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    return prompt\n",
    "\n",
    "# Function to return prompt to critique the LinkedIn post\n",
    "def get_critique_post_prompt() -> str:\n",
    "    \n",
    "    # Define System Content\n",
    "    systemContent = \"\"\"\n",
    "    You are an expert LinkedIn content analyst specializing in evaluating professional posts for maximum engagement and impact.\n",
    "    Your task is to analyze the provided LinkedIn post and deliver two outputs: detailed critique feedback and a binary evaluation (good/rework).\n",
    "    \n",
    "    Input: {post}\n",
    "    \n",
    "    Analysis Framework:\n",
    "\n",
    "    Engagement Potential Assessment:\n",
    "    Hook strength and immediate attention grab\n",
    "    Story arc and narrative flow\n",
    "    Call-to-action effectiveness\n",
    "    Discussion potential\n",
    "    Emotional resonance\n",
    "\n",
    "    Technical Elements Review:\n",
    "    Length optimization (800-1300 characters ideal)\n",
    "    Format and readability\n",
    "    Emoji usage (appropriateness and quantity)\n",
    "    Hashtag implementation\n",
    "    Line break utilization\n",
    "\n",
    "    Content Quality Evaluation:\n",
    "    Value proposition clarity\n",
    "    Professional tone consistency\n",
    "    Authenticity markers\n",
    "    Industry relevance\n",
    "    Audience alignment\n",
    "\n",
    "    Output Structure:\n",
    "    Feedback: Detailed feedback about the post\n",
    "    Verdict: Only output either the word 'good' or 'rework' in lowercase. Remember just a single word and nothing else\n",
    "\n",
    "    Please note do not give the verdict as good when you get the post for the first time\n",
    "    \"\"\"\n",
    "\n",
    "    # List of Messages for the LLM\n",
    "    messages = [(\"system\", systemContent), (\"human\", \"{post}\")]\n",
    "\n",
    "    # Return the Prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Define Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Node 1: Generate Post\n",
    "def generate_node_function(state: State) -> State:\n",
    "\n",
    "    # Get the Prompt\n",
    "    prompt = get_generate_post_prompt()\n",
    "\n",
    "    # Define the chain\n",
    "    generate_post_chain = prompt | llm\n",
    "\n",
    "    # Invoke the Chain        \n",
    "    response = generate_post_chain.invoke({\"topic\": state[\"topic\"], \"critique-feedback\": state[\"critique_feedback\"]})\n",
    "\n",
    "    if state[\"critique_feedback\"] == \"\":\n",
    "        # Update and Return the State\n",
    "        return {\n",
    "            **state,\n",
    "            \"post_content\": response.content\n",
    "        }\n",
    "    else:\n",
    "        # Update and Return the State\n",
    "        return {\n",
    "            **state,\n",
    "            \"post_content_revise\": response.content\n",
    "        }\n",
    "\n",
    "# Node 2: Critique Post\n",
    "def critique_post_node_function (state: State) -> State:\n",
    "\n",
    "    # Get the Prompt\n",
    "    prompt = get_critique_post_prompt()\n",
    "    \n",
    "    # Define the Chain\n",
    "    critique_post_chain = prompt | llm\n",
    "\n",
    "    # Invoke the Chain\n",
    "    if state[\"post_content_revise\"] == \"\":\n",
    "        response = critique_post_chain.invoke({\"post\": state[\"post_content\"]})\n",
    "    else:\n",
    "        response = critique_post_chain.invoke({\"post\": state[\"post_content_revise\"]})\n",
    "\n",
    "    # Get the feedback and Verdict from the response content\n",
    "    parts = response.content.split('Verdict:')\n",
    "        \n",
    "    # Extract feedback (remove 'Feedback: ' prefix and strip whitespace)\n",
    "    feedback = parts[0].replace('Feedback:', '', 1).strip()\n",
    "\n",
    "    # Extract verdict (strip whitespace)\n",
    "    verdict = parts[1].strip()\n",
    "\n",
    "    # Update Iteration\n",
    "    new_iteration = state.get(\"iteration\") + 1\n",
    "\n",
    "    # Update and Return the State\n",
    "    return {\n",
    "        **state,\n",
    "        \"critique_feedback\": feedback,\n",
    "        \"verdict\": verdict,\n",
    "        \"iteration\": new_iteration\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Continue Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_condition(state:State) -> str:\n",
    "\n",
    "    # Get for verdict\n",
    "    if state[\"verdict\"].lower() == \"rework\" and state[\"iteration\"] < 6:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"stop\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Define Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2063f649410>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes to the workflow\n",
    "workflow.add_node(\"generate_post_node\", generate_node_function)\n",
    "workflow.add_node(\"critique_post_node\", critique_post_node_function)\n",
    "\n",
    "# Add a directed edge\n",
    "workflow.add_edge(\"generate_post_node\",\"critique_post_node\")\n",
    "\n",
    "# Add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"critique_post_node\",\n",
    "    lambda x: continue_condition(x),\n",
    "    {\n",
    "        \"continue\": \"generate_post_node\",\n",
    "        \"stop\": END\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"generate_post_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Compile and Execute Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "app = workflow.compile()\n",
    "\n",
    "# Get the user input about the topic of post\n",
    "user_input = input(\"On which topic you want me to generate a LinkedIn post: \")\n",
    "\n",
    "# Initialize state\n",
    "state = {'iteration': 0, 'topic': user_input, 'critique_feedback': \"\", 'post_content_revise': \"\"}\n",
    "\n",
    "# Process through workflow\n",
    "result = app.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: Print the Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original LinkedIn post about {user_input}:\")\n",
    "\n",
    "print(result.get(\"post_content\"))\n",
    "\n",
    "print(f\"\\n Revise LinkedIn post about {user_input}:\")\n",
    "\n",
    "print(result.get(\"post_content_revise\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 1,\n",
       " 'topic': 'LangGraph',\n",
       " 'post_content': \"In the ever-evolving world of technology, it's crucial to stay ahead of the curve. Today, I'd like to introduce you to a tool that's been making waves in the language processing field - LangGraph.\\n\\nLangGraph is not just another tool; it's a revolution in the way we understand and process language data. It's a graph-based language model that leverages the power of machine learning to provide deeper insights into language patterns and structures.\\n\\nImagine being able to visualize the intricate web of connections between words, phrases, and sentences. With LangGraph, this is not just a dream but a reality. It's like having a bird's eye view of a city, where each word is a building, each sentence a street, and the entire language a sprawling metropolis.\\n\\nBut why does this matter to you? Well, if you're in the field of data analysis, AI, machine learning, or even content creation, LangGraph can be a game-changer. It can help you understand your data better, make more accurate predictions, and create more engaging content.\\n\\nI'd love to hear your thoughts on this. How do you think LangGraph can impact your work? Let's start a conversation! #LangGraph #AI #MachineLearning #DataAnalysis\",\n",
       " 'post_content_revise': '',\n",
       " 'critique_feedback': \"Engagement Potential Assessment: The post starts with a strong hook, emphasizing the importance of staying updated in the technology field. The narrative flow is well-structured, introducing the tool, explaining its functionality, and then connecting its relevance to the reader. The call-to-action is clear and encourages discussion. The post lacks emotional resonance, however, as it maintains a very technical tone throughout.\\n\\nTechnical Elements Review: The post's length is optimal for LinkedIn, and the format is readable with good use of paragraphs. There are no emojis used, which is appropriate for the professional tone of the post. The hashtags are relevant and well-implemented. Line breaks are used effectively to enhance readability.\\n\\nContent Quality Evaluation: The value proposition of LangGraph is clearly explained, and the professional tone is consistent throughout the post. The post feels authentic and is highly relevant to the technology and data analysis industry. The post aligns well with the intended audience, which seems to be professionals in data analysis, AI, machine learning, and content creation.\",\n",
       " 'verdict': 'good'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
